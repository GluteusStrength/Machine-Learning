{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4RkYsnvRVxzT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40565,
     "status": "ok",
     "timestamp": 1677242081514,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "4RkYsnvRVxzT",
    "outputId": "e27cb973-13d3-42f9-ee6a-f7fc770ce2f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.1.0-py3-none-any.whl (365 kB)\n",
      "     ------------------------------------- 365.3/365.3 kB 23.7 MB/s eta 0:00:00\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (4.64.1)\n",
      "Collecting cmaes>=0.9.1\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.9.4-py3-none-any.whl (210 kB)\n",
      "     ------------------------------------- 210.5/210.5 kB 13.4 MB/s eta 0:00:00\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.7/78.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
      "Successfully installed Mako-1.2.4 alembic-1.9.4 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.0\n"
     ]
    }
   ],
   "source": [
    "# !pip uninstall sklearn -y\n",
    "# !pip install --upgrade sklearn\n",
    "# !pip install scikit-learn==0.23.1 --user\n",
    "# !pip install pytorch_tabnet\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db23084",
   "metadata": {
    "executionInfo": {
     "elapsed": 5201,
     "status": "ok",
     "timestamp": 1677242119562,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "8db23084"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ac478f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "u75LaHgrlny5",
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1677242126690,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "u75LaHgrlny5"
   },
   "outputs": [],
   "source": [
    "class F1_Macro(Metric):\n",
    "    def __init__(self):\n",
    "        self._name = \"f1\"\n",
    "        self._maximize = True\n",
    "    def __call__(self, y_true, y_score):\n",
    "        y_pred = np.argmax(y_score, axis = 1)\n",
    "        score = f1_score(y_true, y_pred, average = \"macro\")\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b125501a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677242126993,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "b125501a"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rohMcuaFfcIV",
   "metadata": {
    "executionInfo": {
     "elapsed": 1745,
     "status": "ok",
     "timestamp": 1677242129953,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "rohMcuaFfcIV"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mQneD2hhfgRI",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677242129953,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "mQneD2hhfgRI"
   },
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Quality'])\n",
    "\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "YFuPBSZ5fiy5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677242129953,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "YFuPBSZ5fiy5",
    "outputId": "334cd2bb-3869-40ad-b084-8f112ce43b6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# qualitative to quantitative\n",
    "\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "    \n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "icyFsFHyfozg",
   "metadata": {
    "executionInfo": {
     "elapsed": 3364,
     "status": "ok",
     "timestamp": 1677242133313,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "icyFsFHyfozg"
   },
   "outputs": [],
   "source": [
    "# na 80%이상 열 삭제\n",
    "\n",
    "col = train_x.columns\n",
    "col = col[3:]\n",
    "for i in col:\n",
    "    if train_x.loc[:, i].isna().sum() > len(train_x) * 0.8:\n",
    "        train_x.drop(i, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "J712mk5IpwID",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1677242133314,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "J712mk5IpwID"
   },
   "outputs": [],
   "source": [
    "# test에서도 동일하게 삭제\n",
    "\n",
    "test_x = test_x.loc[:, train_x.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "XTScsA2igDc7",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1677242133314,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "XTScsA2igDc7"
   },
   "outputs": [],
   "source": [
    "# # 결측치 0으로 채움\n",
    "# train_x = train_x.fillna(0)\n",
    "# test_x = test_x.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31919154",
   "metadata": {
    "id": "31919154"
   },
   "source": [
    "밑의 코드는 이산형 변수와 연속형 변수를 나름 임의대로 분리한 과정이다.\n",
    "feature의 unique 값이 12개 이하이면 이산형 변수로 그 외에는 연속형 변수로 판단하였다.\n",
    "unique값의 기준을 나름 다시 잘 재정의할 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e97c481",
   "metadata": {
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1677242133613,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "8e97c481"
   },
   "outputs": [],
   "source": [
    "idx = train_x.columns[1:]\n",
    "feat_discrete = []\n",
    "feat_numeric = []\n",
    "for i in idx:\n",
    "    check = train_x.loc[:, i]\n",
    "    if len(np.unique(check)) + 1 <= 13:\n",
    "        feat_discrete.append(i)\n",
    "    else:\n",
    "        feat_numeric.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fd7ee8",
   "metadata": {
    "id": "f5fd7ee8"
   },
   "source": [
    "simpleimputer를 이용하였다. 더 좋은 방법이 있으면 그것을 사용할 예정이다.\n",
    "simpleimpute의 default로는 내가 알기로는 mean값이 default로 채워진다.\n",
    "이산형 변수에 대해서는 strategy로 최빈값을 연속형 변수에는 default인 mean으로 채워 넣었다.\n",
    "impute를 우선 trainset으로 학습을 시키고 동일하게 testset에도 적용시켜 Data Leakage 문제에 저촉되지 않도록 하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8bb8dce",
   "metadata": {
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1677242133941,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "d8bb8dce"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp_continuous = SimpleImputer()\n",
    "imp_discrete = SimpleImputer(strategy = \"median\")\n",
    "target = train_x[\"Y_Class\"]\n",
    "train_x.drop(\"Y_Class\", axis = 1, inplace = True)\n",
    "imp_continuous.fit(train_x.loc[:, feat_numeric])\n",
    "imp_discrete.fit(train_x.loc[:, feat_discrete])\n",
    "imputed_df_train_num = pd.DataFrame(imp_continuous.transform(train_x.loc[:, feat_numeric]), columns = feat_numeric)\n",
    "imputed_df_train_dis = pd.DataFrame(imp_discrete.transform(train_x.loc[:, feat_discrete]), columns = feat_discrete)\n",
    "imputed_df_train = pd.concat([imputed_df_train_num, imputed_df_train_dis], axis = 1)\n",
    "imputed_df_test_num = pd.DataFrame(imp_continuous.transform(test_x.loc[:, feat_numeric]), columns = feat_numeric)\n",
    "imputed_df_test_dis = pd.DataFrame(imp_discrete.transform(test_x.loc[:, feat_discrete]), columns = feat_discrete)\n",
    "imputed_df_test = pd.concat([imputed_df_test_num, imputed_df_test_dis], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69d484f4",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677242133941,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "69d484f4"
   },
   "outputs": [],
   "source": [
    "add_cols = train_x.iloc[:, 0:2]\n",
    "add_col = test_x.iloc[:, 0:2]\n",
    "imputed_df_train = pd.concat([add_cols, imputed_df_train], axis = 1)\n",
    "imputed_df_test = pd.concat([add_col, imputed_df_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a113e01",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677242133941,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "8a113e01"
   },
   "outputs": [],
   "source": [
    "train = imputed_df_train\n",
    "train[\"Y_Class\"] = target\n",
    "test = imputed_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bdfe7a4",
   "metadata": {
    "executionInfo": {
     "elapsed": 1428,
     "status": "ok",
     "timestamp": 1677242135366,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "8bdfe7a4"
   },
   "outputs": [],
   "source": [
    "idx = train.columns\n",
    "col = []\n",
    "# 하나의 값만 들어있는 column 들은 나가리 시킨다.\n",
    "for i in idx:\n",
    "    check = train.loc[:, i]\n",
    "    if len(np.unique(check)) == 1:\n",
    "        col.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0147aa7",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677242135367,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "f0147aa7"
   },
   "outputs": [],
   "source": [
    "train.drop(col, axis = 1, inplace = True)\n",
    "test.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3Qwpo6Snyp0P",
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1677242135664,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "3Qwpo6Snyp0P"
   },
   "outputs": [],
   "source": [
    "# train set의 label encoding을 통해 알 수 있는 점: 이 2개의 column은 범주형 자료다.\n",
    "num_unique = np.array(train.nunique())\n",
    "categorical_columns = [\"LINE\", \"PRODUCT_CODE\"]\n",
    "categorical_dims = {\"LINE\": num_unique[0], \"PRODUCT_CODE\": num_unique[1]}\n",
    "cat_idxs = [i for i, f in enumerate(train.columns) if f in categorical_columns]\n",
    "cat_dims = [categorical_dims[f] for i, f in enumerate(train.columns) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7IksKyrNbdo",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1677242135664,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "d7IksKyrNbdo"
   },
   "outputs": [],
   "source": [
    "train_y = train['Y_Class']\n",
    "train_x = train.drop(columns=['Y_Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "jcPddvU0NMtL",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1677242135954,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "jcPddvU0NMtL"
   },
   "outputs": [],
   "source": [
    "# split dataset\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, stratify=train_y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "kjuvZWKis5Ak",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1677242136832,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "kjuvZWKis5Ak"
   },
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "valid_x = valid_x.to_numpy()\n",
    "valid_y = valid_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "TAMz6vnzWh52",
   "metadata": {
    "id": "TAMz6vnzWh52"
   },
   "outputs": [],
   "source": [
    "cat_idxs = [0, 1]\n",
    "cat_dims = [6, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "UzAj6vHNg21w",
   "metadata": {
    "id": "UzAj6vHNg21w"
   },
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(cat_idxs=cat_idxs,\n",
    "                       cat_dims=cat_dims,\n",
    "                       cat_emb_dim=3,\n",
    "                       optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-2),\n",
    "                       scheduler_params={\"step_size\":50,\n",
    "                                         \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='sparsemax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x46lM1gEg4mt",
   "metadata": {
    "id": "x46lM1gEg4mt"
   },
   "outputs": [],
   "source": [
    "# max_epochs = 2000\n",
    "\n",
    "# clf.fit(X_train=train_x, y_train=train_y,\n",
    "#         eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "#         eval_name=['train', 'valid'],\n",
    "#         eval_metric=['f1'],\n",
    "#         max_epochs=max_epochs, patience=10,\n",
    "#         batch_size=1024, virtual_batch_size=128,\n",
    "#         num_workers=0,\n",
    "#         weights=1,\n",
    "#         drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "rfvFfCR0g1RK",
   "metadata": {
    "id": "rfvFfCR0g1RK"
   },
   "outputs": [],
   "source": [
    "def Objective(trial):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n",
    "    n_da = trial.suggest_int(\"n_da\", 16, 64, step=4)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 3, 10, step=2)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1., 1.5, step=0.1)\n",
    "    cat_emb_dim = trial.suggest_int(\"cat_emb_dim\", 3, 10, step=1)\n",
    "    n_shared = trial.suggest_int(\"n_shared\", 3, 5, step=1)\n",
    "    n_independent = trial.suggest_int(\"n_independent\", 3, 5, step=1)\n",
    "    lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n",
    "    tabnet_params = dict(n_d=n_da,\n",
    "                         n_a=n_da,\n",
    "                         n_steps=n_steps,\n",
    "                         gamma=gamma,\n",
    "                         cat_idxs=cat_idxs,\n",
    "                         cat_dims=cat_dims,\n",
    "                         cat_emb_dim=cat_emb_dim,\n",
    "                         lambda_sparse=lambda_sparse,\n",
    "                         optimizer_fn=torch.optim.Adam,\n",
    "                         optimizer_params=dict(lr=1e-2, weight_decay=1e-5),\n",
    "                         mask_type=mask_type,\n",
    "                         n_shared=n_shared,\n",
    "                         n_independent=n_independent,\n",
    "                         scheduler_params=dict(mode=\"min\",\n",
    "                                               patience=trial.suggest_int(\"patienceScheduler\",9, 10, step=1), # changing sheduler patience to be lower than early stopping patience \n",
    "                                               min_lr=1e-5,\n",
    "                                               factor=0.5,),\n",
    "                        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                        device_name = device,\n",
    "                        verbose=0\n",
    "                        ) #early stopping\n",
    "    kf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    CV_score_array = []\n",
    "    for train_index, test_index in kf.split(train_x, train_y):\n",
    "        X_train, X_valid = train_x[train_index], train_x[test_index]\n",
    "        y_train, y_valid = train_y[train_index], train_y[test_index]\n",
    "        classifier = TabNetClassifier(**tabnet_params)\n",
    "        classifier.fit(X_train=X_train, y_train=y_train,\n",
    "                       eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                       eval_name = [\"train\", \"valid\"],\n",
    "                       patience=trial.suggest_int(\"patience\", 25, 30, step=5),\n",
    "                       max_epochs=trial.suggest_int('epochs', 500, 1000, step=100),\n",
    "                       batch_size=24, virtual_batch_size=8,\n",
    "                       eval_metric=[\"logloss\", 'f1'])\n",
    "        CV_score_array.append(classifier.best_cost)\n",
    "    avg = np.mean(CV_score_array)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "Z4fecZEysEEs",
   "metadata": {
    "id": "Z4fecZEysEEs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-25 12:46:15,714]\u001b[0m A new study created in memory with name: TabNet optimization\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 37 and best_valid_f1 = 0.57619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 37 and best_valid_f1 = 0.46297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 42 and best_valid_f1 = 0.47193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 21 and best_valid_f1 = 0.44444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 2 and best_valid_f1 = 0.42834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 18 and best_valid_f1 = 0.45556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 30 and best_valid_f1 = 0.54167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 23 and best_valid_f1 = 0.45913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 23 and best_valid_f1 = 0.66402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 14 and best_valid_f1 = 0.53333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 13:26:26,428]\u001b[0m Trial 0 finished with value: 0.503758819188122 and parameters: {'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 9, 'gamma': 1.0, 'cat_emb_dim': 7, 'n_shared': 3, 'n_independent': 3, 'lambda_sparse': 3.7689342125186537e-05, 'patienceScheduler': 9, 'patience': 30, 'epochs': 900}. Best is trial 0 with value: 0.503758819188122.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 42 and best_valid_f1 = 0.5549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 41 and best_valid_f1 = 0.51737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 1 and best_valid_f1 = 0.52706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 28 and best_valid_f1 = 0.4386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 37 and best_valid_f1 = 0.53074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 27 with best_epoch = 2 and best_valid_f1 = 0.4907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 38 with best_epoch = 13 and best_valid_f1 = 0.46949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 45 with best_epoch = 20 and best_valid_f1 = 0.45485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 42 and best_valid_f1 = 0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 15 and best_valid_f1 = 0.60479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 14:02:04,494]\u001b[0m Trial 1 finished with value: 0.5057491692123243 and parameters: {'mask_type': 'entmax', 'n_da': 32, 'n_steps': 9, 'gamma': 1.3, 'cat_emb_dim': 4, 'n_shared': 3, 'n_independent': 5, 'lambda_sparse': 1.9685894255846567e-05, 'patienceScheduler': 9, 'patience': 25, 'epochs': 600}. Best is trial 0 with value: 0.503758819188122.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 28 and best_valid_f1 = 0.56749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 1 and best_valid_f1 = 0.40048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 101 with best_epoch = 71 and best_valid_f1 = 0.59503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 17 and best_valid_f1 = 0.44737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 38 and best_valid_f1 = 0.65079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 59 with best_epoch = 29 and best_valid_f1 = 0.47599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 14 and best_valid_f1 = 0.46923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 32 and best_valid_f1 = 0.4178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 6 and best_valid_f1 = 0.5082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 25 and best_valid_f1 = 0.5015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 14:33:22,623]\u001b[0m Trial 2 finished with value: 0.5033876315188606 and parameters: {'mask_type': 'sparsemax', 'n_da': 36, 'n_steps': 7, 'gamma': 1.2, 'cat_emb_dim': 7, 'n_shared': 3, 'n_independent': 4, 'lambda_sparse': 4.778939419354901e-06, 'patienceScheduler': 9, 'patience': 30, 'epochs': 900}. Best is trial 2 with value: 0.5033876315188606.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 32 and best_valid_f1 = 0.53528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 7 and best_valid_f1 = 0.46963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 49 and best_valid_f1 = 0.52308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 13 and best_valid_f1 = 0.45833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 79 with best_epoch = 49 and best_valid_f1 = 0.56481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 30 and best_valid_f1 = 0.45375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 50 and best_valid_f1 = 0.47193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 45 and best_valid_f1 = 0.39649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 34 and best_valid_f1 = 0.56624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 21 and best_valid_f1 = 0.56162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 15:01:45,729]\u001b[0m Trial 3 finished with value: 0.5001155555606356 and parameters: {'mask_type': 'sparsemax', 'n_da': 16, 'n_steps': 5, 'gamma': 1.2, 'cat_emb_dim': 3, 'n_shared': 4, 'n_independent': 3, 'lambda_sparse': 2.743730065862055e-06, 'patienceScheduler': 9, 'patience': 30, 'epochs': 1000}. Best is trial 3 with value: 0.5001155555606356.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 45 and best_valid_f1 = 0.63333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 63 with best_epoch = 38 and best_valid_f1 = 0.50547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 15 and best_valid_f1 = 0.39897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 10 and best_valid_f1 = 0.35544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 70 with best_epoch = 45 and best_valid_f1 = 0.53889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 17 and best_valid_f1 = 0.48176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 76 with best_epoch = 51 and best_valid_f1 = 0.44372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 3 and best_valid_f1 = 0.42857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 36 with best_epoch = 11 and best_valid_f1 = 0.42551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 32 and best_valid_f1 = 0.48823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 15:41:12,673]\u001b[0m Trial 4 finished with value: 0.4699891534198941 and parameters: {'mask_type': 'sparsemax', 'n_da': 28, 'n_steps': 9, 'gamma': 1.2, 'cat_emb_dim': 10, 'n_shared': 5, 'n_independent': 4, 'lambda_sparse': 0.00010044667748314484, 'patienceScheduler': 9, 'patience': 25, 'epochs': 700}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 18 and best_valid_f1 = 0.40684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 13 and best_valid_f1 = 0.49133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 9 and best_valid_f1 = 0.45324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 97 with best_epoch = 67 and best_valid_f1 = 0.45185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 4 and best_valid_f1 = 0.48519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 56 and best_valid_f1 = 0.59926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 0 and best_valid_f1 = 0.52451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 30 with best_epoch = 0 and best_valid_f1 = 0.41919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 14 and best_valid_f1 = 0.53298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 12 and best_valid_f1 = 0.46825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 16:00:56,662]\u001b[0m Trial 5 finished with value: 0.4832645555000511 and parameters: {'mask_type': 'entmax', 'n_da': 28, 'n_steps': 3, 'gamma': 1.4, 'cat_emb_dim': 4, 'n_shared': 4, 'n_independent': 5, 'lambda_sparse': 0.0004825192265591259, 'patienceScheduler': 9, 'patience': 30, 'epochs': 900}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 43 and best_valid_f1 = 0.62281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 33 with best_epoch = 8 and best_valid_f1 = 0.46933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 7 and best_valid_f1 = 0.47492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 37 and best_valid_f1 = 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 0 and best_valid_f1 = 0.41869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 54 with best_epoch = 29 and best_valid_f1 = 0.53726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 108 with best_epoch = 83 and best_valid_f1 = 0.73308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 1 and best_valid_f1 = 0.46576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 23 and best_valid_f1 = 0.58201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 25 with best_epoch = 0 and best_valid_f1 = 0.57083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 18:38:22,776]\u001b[0m Trial 6 finished with value: 0.5380975618825354 and parameters: {'mask_type': 'sparsemax', 'n_da': 60, 'n_steps': 5, 'gamma': 1.3, 'cat_emb_dim': 7, 'n_shared': 4, 'n_independent': 5, 'lambda_sparse': 0.0004211875239280485, 'patienceScheduler': 9, 'patience': 25, 'epochs': 1000}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 36 and best_valid_f1 = 0.61111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 13 and best_valid_f1 = 0.42017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 41 and best_valid_f1 = 0.4379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 83 with best_epoch = 53 and best_valid_f1 = 0.48446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 65 with best_epoch = 35 and best_valid_f1 = 0.69146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 21 and best_valid_f1 = 0.44213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 26 and best_valid_f1 = 0.39649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 51 and best_valid_f1 = 0.61344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 22 and best_valid_f1 = 0.4307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 30 and best_valid_f1 = 0.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 19:25:39,844]\u001b[0m Trial 7 finished with value: 0.5107275258721291 and parameters: {'mask_type': 'sparsemax', 'n_da': 36, 'n_steps': 7, 'gamma': 1.1, 'cat_emb_dim': 4, 'n_shared': 5, 'n_independent': 4, 'lambda_sparse': 6.695384710811474e-05, 'patienceScheduler': 9, 'patience': 30, 'epochs': 800}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 71 with best_epoch = 41 and best_valid_f1 = 0.62037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 81 with best_epoch = 51 and best_valid_f1 = 0.55006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 60 with best_epoch = 30 and best_valid_f1 = 0.5163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 57 and best_valid_f1 = 0.65192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 97 with best_epoch = 67 and best_valid_f1 = 0.59259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 34 with best_epoch = 4 and best_valid_f1 = 0.4171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 105 with best_epoch = 75 and best_valid_f1 = 0.66697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 45 and best_valid_f1 = 0.59286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 14 and best_valid_f1 = 0.51906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 36 and best_valid_f1 = 0.5794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 19:52:52,227]\u001b[0m Trial 8 finished with value: 0.5706639612935981 and parameters: {'mask_type': 'entmax', 'n_da': 56, 'n_steps': 3, 'gamma': 1.0, 'cat_emb_dim': 4, 'n_shared': 3, 'n_independent': 5, 'lambda_sparse': 1.4807456732722638e-06, 'patienceScheduler': 10, 'patience': 30, 'epochs': 700}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 39 with best_epoch = 14 and best_valid_f1 = 0.53899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 19 and best_valid_f1 = 0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 31 with best_epoch = 6 and best_valid_f1 = 0.40167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 73 with best_epoch = 48 and best_valid_f1 = 0.57028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 49 with best_epoch = 24 and best_valid_f1 = 0.52961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 39 and best_valid_f1 = 0.57619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 27 and best_valid_f1 = 0.58558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 12 and best_valid_f1 = 0.4693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 1 and best_valid_f1 = 0.48264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 41 and best_valid_f1 = 0.65067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 20:20:51,776]\u001b[0m Trial 9 finished with value: 0.5286936818005803 and parameters: {'mask_type': 'entmax', 'n_da': 40, 'n_steps': 3, 'gamma': 1.2, 'cat_emb_dim': 4, 'n_shared': 5, 'n_independent': 4, 'lambda_sparse': 0.0006812046928375439, 'patienceScheduler': 9, 'patience': 25, 'epochs': 600}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 30 and best_valid_f1 = 0.49026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 44 with best_epoch = 19 and best_valid_f1 = 0.64156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 42 and best_valid_f1 = 0.49872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 50 with best_epoch = 25 and best_valid_f1 = 0.57619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 30 and best_valid_f1 = 0.57098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 17 and best_valid_f1 = 0.64105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 37 and best_valid_f1 = 0.69895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 31 and best_valid_f1 = 0.41586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 33 and best_valid_f1 = 0.56902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 47 with best_epoch = 22 and best_valid_f1 = 0.54624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 21:09:24,636]\u001b[0m Trial 10 finished with value: 0.5648832647441211 and parameters: {'mask_type': 'sparsemax', 'n_da': 48, 'n_steps': 9, 'gamma': 1.5, 'cat_emb_dim': 10, 'n_shared': 5, 'n_independent': 3, 'lambda_sparse': 0.00012621375500947792, 'patienceScheduler': 10, 'patience': 25, 'epochs': 500}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 35 with best_epoch = 10 and best_valid_f1 = 0.47393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 32 with best_epoch = 7 and best_valid_f1 = 0.52063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 26 with best_epoch = 1 and best_valid_f1 = 0.37967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 28 with best_epoch = 3 and best_valid_f1 = 0.49449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 28 and best_valid_f1 = 0.5996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 37 with best_epoch = 12 and best_valid_f1 = 0.43169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 39 and best_valid_f1 = 0.53293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 52 with best_epoch = 27 and best_valid_f1 = 0.40526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 62 with best_epoch = 37 and best_valid_f1 = 0.64259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 23 and best_valid_f1 = 0.48823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[32m[I 2023-02-25 21:36:53,181]\u001b[0m Trial 11 finished with value: 0.4969029742280534 and parameters: {'mask_type': 'entmax', 'n_da': 24, 'n_steps': 5, 'gamma': 1.5, 'cat_emb_dim': 10, 'n_shared': 4, 'n_independent': 4, 'lambda_sparse': 0.0002748698113937471, 'patienceScheduler': 10, 'patience': 25, 'epochs': 800}. Best is trial 4 with value: 0.4699891534198941.\u001b[0m\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\distributions.py:716: UserWarning: The distribution is specified by [3, 10] and step=2, but the range is not divisible by `step`. It will be replaced by [3, 9].\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping occurred at epoch 78 with best_epoch = 48 and best_valid_f1 = 0.46252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n",
      "\u001b[33m[W 2023-02-25 21:42:26,536]\u001b[0m Trial 12 failed with parameters: {'mask_type': 'entmax', 'n_da': 24, 'n_steps': 7, 'gamma': 1.4, 'cat_emb_dim': 9, 'n_shared': 5, 'n_independent': 5, 'lambda_sparse': 0.0008766879211993953, 'patienceScheduler': 9, 'patience': 30, 'epochs': 700} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5516\\332815910.py\", line 38, in Objective\n",
      "    classifier.fit(X_train=X_train, y_train=y_train,\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 241, in fit\n",
      "    self._train_epoch(train_dataloader)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 457, in _train_epoch\n",
      "    batch_logs = self._train_batch(X, y)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py\", line 495, in _train_batch\n",
      "    output, M_loss = self.network(X)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 585, in forward\n",
      "    x = self.embedder(x)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\user\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\tab_network.py\", line 858, in forward\n",
      "    cols.append(x[:, feat_init_idx].float().view(-1, 1))\n",
      "KeyboardInterrupt\n",
      "\u001b[33m[W 2023-02-25 21:42:26,537]\u001b[0m Trial 12 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5516\\1677416030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'minimize'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'TabNet optimization'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mObjective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \"\"\"\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5516\\332815910.py\u001b[0m in \u001b[0;36mObjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTabNetClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtabnet_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         classifier.fit(X_train=X_train, y_train=y_train,\n\u001b[0m\u001b[0;32m     39\u001b[0m                        \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                        \u001b[0meval_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"valid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations)\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[1;31m# Apply predict epoch to all eval sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py\u001b[0m in \u001b[0;36m_train_batch\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtabnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_tabnet\\tab_network.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[1;31m# Enumerate through continuous idx boolean mask to apply embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_continuous\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m                 \u001b[0mcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_init_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m                 cols.append(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize', study_name='TabNet optimization')\n",
    "study.optimize(Objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q8PcL_Gcsop4",
   "metadata": {
    "id": "Q8PcL_Gcsop4"
   },
   "outputs": [],
   "source": [
    "TabNet_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "GOen2w92bFvU",
   "metadata": {
    "executionInfo": {
     "elapsed": 465,
     "status": "ok",
     "timestamp": 1677242209754,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "GOen2w92bFvU"
   },
   "outputs": [],
   "source": [
    "TabNet_params = {'mask_type': 'entmax',\n",
    "                 'n_da': 64,\n",
    "                 'n_steps': 5,\n",
    "                 'gamma': 1.1,\n",
    "                 'cat_emb_dim': 10,\n",
    "                 'n_shared': 4,\n",
    "                 'n_independent': 3,\n",
    "                 'lambda_sparse': 0.0009570756759623438,\n",
    "                 'patienceScheduler': 9,\n",
    "                 'patience': 25,\n",
    "                 'epochs': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "PaqZFNumvsff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1677242211231,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "PaqZFNumvsff",
    "outputId": "12279291-a604-4183-e976-65add033199d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mask_type': 'entmax',\n",
       " 'n_da': 64,\n",
       " 'n_steps': 5,\n",
       " 'gamma': 1.1,\n",
       " 'cat_emb_dim': 10,\n",
       " 'n_shared': 4,\n",
       " 'n_independent': 3,\n",
       " 'lambda_sparse': 0.0009570756759623438,\n",
       " 'patienceScheduler': 9,\n",
       " 'patience': 25,\n",
       " 'epochs': 300}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TabNet_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YXPGWje5vyd7",
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1677242223108,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "YXPGWje5vyd7"
   },
   "outputs": [],
   "source": [
    "final_params = dict(n_d=TabNet_params['n_da'], \n",
    "                    n_a=TabNet_params['n_da'],\n",
    "                    n_steps=TabNet_params['n_steps'],\n",
    "                    gamma=TabNet_params['gamma'],\n",
    "                    cat_emb_dim=TabNet_params['cat_emb_dim'],\n",
    "                    lambda_sparse=TabNet_params['lambda_sparse'],\n",
    "                    optimizer_fn=torch.optim.Adam,\n",
    "                    optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n",
    "                    mask_type=TabNet_params['mask_type'],\n",
    "                    n_shared=TabNet_params['n_shared'],\n",
    "                    scheduler_params=dict(mode=\"min\",\n",
    "                                          patience=TabNet_params['patienceScheduler'],\n",
    "                                          min_lr=1e-5,\n",
    "                                          factor=0.5,),\n",
    "                     scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "                     verbose=1,\n",
    "                     )\n",
    "epochs = TabNet_params['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qvD6HRoB69FD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3948026,
     "status": "ok",
     "timestamp": 1677246173371,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "qvD6HRoB69FD",
    "outputId": "ee27d993-52b1-45dc-d0d8-66ff53ffcfa6"
   },
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(**final_params)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(train_x, train_y):\n",
    "    X_train, X_valid = train_x[train_index], train_x[test_index]\n",
    "    y_train, y_valid = train_y[train_index], train_y[test_index]\n",
    "    clf.fit(X_train=train_x, y_train=train_y,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            patience=TabNet_params['patience'],\n",
    "            max_epochs=epochs,\n",
    "            batch_size=24, virtual_batch_size=8,\n",
    "            eval_metric=['f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g_wfPsjr72LS",
   "metadata": {
    "executionInfo": {
     "elapsed": 2319,
     "status": "ok",
     "timestamp": 1677246182338,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "g_wfPsjr72LS"
   },
   "outputs": [],
   "source": [
    "preds = clf.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9_cx9bSX8JP-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 300,
     "status": "ok",
     "timestamp": 1677246191599,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "9_cx9bSX8JP-",
    "outputId": "0274768d-dd1a-455e-97fd-043c94ec7ccd"
   },
   "outputs": [],
   "source": [
    "np.unique(preds, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ca7148",
   "metadata": {
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1677246247619,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "64ca7148"
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/content/drive/MyDrive/Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43d33954",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1677246248927,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "43d33954"
   },
   "outputs": [],
   "source": [
    "submit['Y_Class'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c236901",
   "metadata": {
    "executionInfo": {
     "elapsed": 467,
     "status": "ok",
     "timestamp": 1677246251219,
     "user": {
      "displayName": "이현준",
      "userId": "05598432428551997234"
     },
     "user_tz": -540
    },
    "id": "0c236901"
   },
   "outputs": [],
   "source": [
    "submit.to_csv('/content/drive/MyDrive/Data/final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5G5hD0zdqrmW",
   "metadata": {
    "id": "5G5hD0zdqrmW"
   },
   "outputs": [],
   "source": [
    "clf.save_model('/content/drive/MyDrive/Data/best_tabne')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
